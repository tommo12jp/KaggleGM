{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7baa288a-fda7-4898-b51e-0f2d13becb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "031abef2-16c8-4a14-9688-047e1459e50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# マッピング用の事象\n",
    "mapping = {\n",
    "    \"Freezing\": 0,\n",
    "    \"Warm\":1,\n",
    "    \"Cold\":2,\n",
    "    \"Boiling Hot\":3,\n",
    "    \"Hot\":4,\n",
    "    \"Lava Hot\":5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f77adf5-3b46-4b63-b4d7-c006d23cd854",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# CSVファイルの読み込み\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./train.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py:1217\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1214\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1228\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py:789\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    785\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    788\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 789\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    796\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    797\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    798\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './train.csv'"
     ]
    }
   ],
   "source": [
    "# CSVファイルの読み込み\n",
    "df = pd.read_csv(\"./train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4376cd69-055a-4af2-9d8c-8c7983deec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# マッピング辞書による置換\n",
    "df.loc[:, \"ord_2\"] = df.ord_2.map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa93af0e-9586-441e-9d3a-19976a469ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    142726\n",
       "1.0    124239\n",
       "2.0     97822\n",
       "3.0     84790\n",
       "4.0     67508\n",
       "5.0     64840\n",
       "Name: ord_2, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84bf1bb8-ff01-4f54-9c24-bcee3020d13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1aa3ae2d-ab0c-4331-b0fc-67a499d02c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CSVファイルの読み込み\n",
    "df = pd.read_csv(\"./train.csv\")\n",
    "\n",
    "# 欠損値をNONEの文字列に置換\n",
    "df.loc[:, \"ord_2\"] = df.ord_2.fillna(\"NONE\")\n",
    "\n",
    "\n",
    "# 初期化\n",
    "lbl_enc = preprocessing.LabelEncoder()\n",
    "\n",
    "# 値を変換\n",
    "df.loc[:, \"ord_2\"] = lbl_enc.fit_transform(df.ord_2.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41411191-47e1-4c28-be1d-4f8cca391d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    }
   ],
   "source": [
    "# ord_2は名義変数であり、数値に順序性や大小関係はないので、「0-5」などの値をそのままモデルにインプットすることはできない\n",
    "# そこで、二値変数に変換する\n",
    "import numpy as np\n",
    "\n",
    "# 列の特徴量を作成\n",
    "example = np.array(\n",
    "    [\n",
    "        [0, 0, 1],\n",
    "        [1, 0, 0],\n",
    "        [1, 0, 1]\n",
    "    ]\n",
    ")\n",
    "\n",
    "# バイト数の表示\n",
    "print(example.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9c7da2e-efcd-48a1-b350-ee5be31cac0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "# 二値変数をCSR方式の疎行列で表現\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "# 列の特徴量を作成\n",
    "example = np.array(\n",
    "    [\n",
    "        [0, 0, 1],\n",
    "        [1, 0, 0],\n",
    "        [1, 0, 1]\n",
    "    ]\n",
    ")\n",
    "\n",
    "# numpyの配列を疎行列に変換\n",
    "sparse_example = sparse.csc_matrix(example)\n",
    "\n",
    "# バイト数の表示\n",
    "print(sparse_example.data.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2951e3d-8d5f-4dcb-94cc-cbd3d6f959e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000000\n",
      "3998616\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "n_rows = 1000\n",
    "n_cols = 10000\n",
    "\n",
    "example = np.random.binomial(1, p=0.05, size=(n_rows, n_cols))\n",
    "\n",
    "print(example.nbytes)\n",
    "\n",
    "# numpyの配列を疎行列に変換\n",
    "sparse_example = sparse.csc_matrix(example)\n",
    "\n",
    "print(sparse_example.data.nbytes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "218ed1e2-4481-4693-a429-6c08b989b35c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000000\n",
      "80000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "example = np.random.randint(1000, size=10000)\n",
    "\n",
    "# 初期化\n",
    "ohe = preprocessing.OneHotEncoder(sparse=False)\n",
    "\n",
    "# one hotベクトルに変換\n",
    "ohe_example = ohe.fit_transform(example.reshape(-1, 1))\n",
    "\n",
    "# 密結合のサイズを表示\n",
    "print(ohe_example.nbytes)\n",
    "\n",
    "# 再初期化\n",
    "ohe_2 = preprocessing.OneHotEncoder(sparse=True)\n",
    "\n",
    "# one hotベクトルに変換\n",
    "ohe_example = ohe_2.fit_transform(example.reshape(-1, 1))\n",
    "\n",
    "# 密結合のサイズを表示\n",
    "print(ohe_example.data.nbytes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbbf40c5-2eb0-483b-b462-10a7b8fb8382",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"new_feature\"]= (\n",
    "    df.ord_1.astype(str)\n",
    "    + \"_\"\n",
    "    + df.ord_2.astype(str)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c25e092-c737-450b-b5ed-70e402d8a0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Freezing       142726\n",
       "Warm           124239\n",
       "Cold            97822\n",
       "Boiling Hot     84790\n",
       "Hot             67508\n",
       "Lava Hot        64840\n",
       "Name: ord_2, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.ord_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f3f0bb14-3642-46f6-882f-bdc2985420bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Freezing       142726\n",
       "Warm           124239\n",
       "Cold            97822\n",
       "Boiling Hot     84790\n",
       "Hot             67508\n",
       "Lava Hot        64840\n",
       "NONE            18075\n",
       "Name: ord_2, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, \"ord_2\"] = df.ord_2.fillna(\"NONE\")\n",
    "df.ord_2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b404d809-032f-4766-80ef-d2908ab6d2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下のように置換して補完を行う\n",
    "# 欠損値：\"NONE\"\n",
    "# 数値：文字列\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# CSVファイルの読み込み\n",
    "train = pd.read_csv(\"./train.csv\")\n",
    "\n",
    "# CSVファイルの読み込み\n",
    "test = pd.read_csv(\"./test.csv\")\n",
    "\n",
    "# 評価用データセットに擬似列を追加\n",
    "test.loc[:, \"target\"] = -1\n",
    "\n",
    "#train-testの結合\n",
    "data = pd.concat([train, test]).reset_index(drop=True)\n",
    "\n",
    "# 特徴量として扱う列をリストに格納\n",
    "# インデックスと目的変数の列は処理対象外\n",
    "features = [x for x in train.columns if x not in [\"id\", \"target\"]]\n",
    "\n",
    "\n",
    "# 個々の特徴量についてのループ\n",
    "for feat in features:\n",
    "    # 初期化\n",
    "    lbl_enc = preprocessing.LabelEncoder()\n",
    "    \n",
    "    # 欠損値を文字列で補完し、全ての値を文字列に置換\n",
    "    # 置換後の文字列をラベル＝ラベルIDとして使用する\n",
    "    temp_col = data[feat].fillna(\"NONE\").astype(str).values\n",
    "    \n",
    "    # サンプルデータの列をラベルに変換する\n",
    "    data.loc[:, feat] = lbl_enc.fit_transform(temp_col)\n",
    "    \n",
    "# train/valに分割\n",
    "train = data[data.target != -1].reset_index(drop=True)\n",
    "test = data[data.target == -1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fd0b563-1703-4a67-8ac6-616b6268ca20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_folds.py\n",
    "# StratifiedKFoldを使ってデータセットを分割する\n",
    "import pandas as pd\n",
    "from sklearn import model_selection\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # サンプルのCSVファイルをpandasに読み込む\n",
    "    df = pd.read_csv(\"./train.csv\")\n",
    "    \n",
    "    # kfold列を追加して初期化\n",
    "    df[\"kfold\"] = -1\n",
    "\n",
    "    # サンプルをシャッフル\n",
    "    df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    # 目的変数の取り出し\n",
    "    y = df.target.values\n",
    "    \n",
    "    # Startified K Foldクラスの初期化\n",
    "    kf = model_selection.StratifiedKFold(n_splits=5)\n",
    "\n",
    "\n",
    "    # kfold列を埋める\n",
    "    for fold, (t_, v_) in enumerate(kf.split(X=df, y=y)):\n",
    "        df.loc[v_, 'kfold'] = fold\n",
    "    \n",
    "    # データセットを新しい名前で保存\n",
    "    df.to_csv(\"./train_folds.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9ab808d-0624-447c-a507-ffae4813ccdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./train_folds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c9d6ee4-f724-49d7-b478-4db619a07581",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    120000\n",
       "1    120000\n",
       "2    120000\n",
       "3    120000\n",
       "4    120000\n",
       "Name: kfold, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.kfold.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c95c051-9860-4031-8e7d-37069f718926",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7845043854397131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7873640539576067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.788386046790077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7831034515610602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7872046311030512\n"
     ]
    }
   ],
   "source": [
    "# ohe_logres.py\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def run(fold: int):\n",
    "    # サンプルのCSVファイルをpandasに読み込む\n",
    "    df = pd.read_csv(\"./train_folds.csv\")\n",
    "    \n",
    "    # \n",
    "    features = [\n",
    "        f for f in df.columns if f not in (\"id\", \"target\", \"kfold\")\n",
    "    \n",
    "    ]\n",
    "    \n",
    "    # 個々の特徴量についてのループ\n",
    "    for col in features:\n",
    "        # 欠損値を文字列で補完し、全ての値を文字列に置換\n",
    "        # 置換後の文字列をラベル＝ラベルIDとして使用する\n",
    "        df.loc[:, col] = df[col].fillna(\"NONE\").astype(str).values\n",
    "        \n",
    "        # 引数と一致しないkfoldのデータを学習\n",
    "        df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "        \n",
    "        # 引数と一致するkfoldのデータを検証\n",
    "        df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "        \n",
    "        # 初期化\n",
    "        ohe = preprocessing.OneHotEncoder()\n",
    "        \n",
    "        \n",
    "    #train-testの結合\n",
    "    full_data = pd.concat([df_train[features], df_valid[features]],\n",
    "                          axis=0\n",
    "                         )\n",
    "    #oheを学習\n",
    "    ohe.fit(full_data[features])\n",
    "    \n",
    "    # 学習データセットを変換\n",
    "    x_train = ohe.transform(df_train[features])\n",
    "    \n",
    "    # 検証データセットを変換\n",
    "    x_valid = ohe.transform(df_valid[features])\n",
    "        \n",
    "    # モデルを初期化して学習\n",
    "    model = linear_model.LogisticRegression()\n",
    "    model.fit(x_train, df_train.target.values)\n",
    "    \n",
    "    #  検証データセットを予測\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    \n",
    "    # AUCを算出\n",
    "    auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)\n",
    "    \n",
    "    print(auc)\n",
    "    \n",
    "if __name__== \"__main__\":\n",
    "    for fold_ in range(5):\n",
    "        run(fold_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dad01918-b57f-4dd3-80c3-f5725045b80b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7845043854397131\n",
      "0.7873640539576067\n",
      "0.788386046790077\n",
      "0.7831034515610602\n",
      "0.7872046311030512\n"
     ]
    }
   ],
   "source": [
    "!python3 -W ignore ohe_logres.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdacaa25-bd68-4adb-a7ec-8881281e6182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7174618974147643\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50/1190717953.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfold_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_50/1190717953.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(fold)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;31m# モデルの初期化と学習\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    443\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    935\u001b[0m         \"\"\"\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    938\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    418\u001b[0m             )\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# lbl_rf.py\n",
    "from sklearn import ensemble\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "\n",
    "def run(fold: int):\n",
    "    # サンプルのCSVファイルをpandasに読み込む\n",
    "    df = pd.read_csv(\"./train_folds.csv\")\n",
    "    \n",
    "    # \n",
    "    features = [\n",
    "        f for f in df.columns if f not in (\"id\", \"target\", \"kfold\")\n",
    "    \n",
    "    ]\n",
    "    \n",
    "    # 個々の特徴量についてのループ\n",
    "    for col in features:\n",
    "        # 欠損値を文字列で補完し、全ての値を文字列に置換\n",
    "        # 置換後の文字列をラベル＝ラベルIDとして使用する\n",
    "        df.loc[:, col] = df[col].fillna(\"NONE\").astype(str).values\n",
    "        \n",
    "    # 特徴量のラベルエンコーディング\n",
    "    for col in features:\n",
    "        # 初期化\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        \n",
    "        # ラベルエンコーダの学習\n",
    "        lbl.fit(df[col])\n",
    "        \n",
    "        # データセットの変換\n",
    "        df.loc[:, col] = lbl.transform(df[col])\n",
    "        \n",
    "    # 引数と一致しないkfoldのデータを学習\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "\n",
    "    # 引数と一致するkfoldのデータを検証\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    # 学習データセットを準備\n",
    "    x_train = df_train[features].values\n",
    "    \n",
    "    # 検証データセットを変換\n",
    "    x_valid = df_valid[features].values\n",
    "        \n",
    "    # モデルの初期化と学習\n",
    "    model = ensemble.RandomForestClassifier(n_jobs=1)\n",
    "    model.fit(x_train, df_train.target.values)\n",
    "    \n",
    "    \n",
    "    #  検証データセットを予測\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    \n",
    "    # AUCを算出\n",
    "    auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)\n",
    "    \n",
    "    print(auc)\n",
    "    \n",
    "if __name__== \"__main__\":\n",
    "    for fold_ in range(5):\n",
    "        run(fold_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38187fdc-79b5-421a-8f16-fe7d87bac3fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /usr/local/lib/python3.8/dist-packages (1.5.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from xgboost) (1.22.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from xgboost) (1.7.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "444cfc71-bb11-47ea-bf00-942df84aa580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:44:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50/3839811065.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfold_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_50/3839811065.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(fold)\u001b[0m\n\u001b[1;32m     51\u001b[0m         )\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1248\u001b[0m         )\n\u001b[1;32m   1249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m         self._Booster = train(\n\u001b[0m\u001b[1;32m   1251\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mtrain_dmatrix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \"\"\"\n\u001b[0;32m--> 188\u001b[0;31m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[1;32m    189\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1680\u001b[0;31m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[1;32m   1681\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# lbl_xgb.py\n",
    "import xgboost as xgb\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def run(fold: int):\n",
    "    # サンプルのCSVファイルをpandasに読み込む\n",
    "    df = pd.read_csv(\"./train_folds.csv\")\n",
    "    \n",
    "    # \n",
    "    features = [\n",
    "        f for f in df.columns if f not in (\"id\", \"target\", \"kfold\")\n",
    "    \n",
    "    ]\n",
    "    \n",
    "    # 個々の特徴量についてのループ\n",
    "    for col in features:\n",
    "        # 欠損値を文字列で補完し、全ての値を文字列に置換\n",
    "        # 置換後の文字列をラベル＝ラベルIDとして使用する\n",
    "        df.loc[:, col] = df[col].fillna(\"NONE\").astype(str).values\n",
    "        \n",
    "    # 特徴量のラベルエンコーディング\n",
    "    for col in features:\n",
    "        # 初期化\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        \n",
    "        # ラベルエンコーダの学習\n",
    "        lbl.fit(df[col])\n",
    "        \n",
    "        # データセットの変換\n",
    "        df.loc[:, col] = lbl.transform(df[col])\n",
    "        \n",
    "    # 引数と一致しないkfoldのデータを学習\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "\n",
    "    # 引数と一致するkfoldのデータを検証\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    # 学習データセットを準備\n",
    "    x_train = df_train[features].values\n",
    "    \n",
    "    # 検証データセットを変換\n",
    "    x_valid = df_valid[features].values\n",
    "        \n",
    "    # モデルの初期化と学習\n",
    "    model = xgb.XGBClassifier(\n",
    "        n_jobs=1,\n",
    "        max_depth=7,\n",
    "        n_estimators=200\n",
    "        )\n",
    "        \n",
    "    model.fit(x_train, df_train.target.values)\n",
    "    \n",
    "    \n",
    "    #  検証データセットを予測\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    \n",
    "    # AUCを算出\n",
    "    auc = metrics.roc_auc_score(df_valid.target.values, valid_preds)\n",
    "    \n",
    "    print(auc)\n",
    "    \n",
    "if __name__== \"__main__\":\n",
    "    for fold_ in range(5):\n",
    "        run(fold_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ff4e367d-3001-43e5-b16c-4a504b67dde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [\n",
    "    \"age\",\n",
    "    \"fnlwgt\",\n",
    "    \"capital-gain\",\n",
    "    \"capital-loss\",\n",
    "    \"hours-per-week\"\n",
    "]\n",
    "df = df.drop(num_cols, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d6a75365-7130-434f-94eb-3fae8ca1bb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 目的変数を0と1に置換\n",
    "target_mapping = {\n",
    "    \"<=50K\": 0,\n",
    "    \">50K\": 1\n",
    "}\n",
    "df[\"income\"] = df.income.map(target_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "57c0ed83-3dd4-4532-a7fb-894d3b3e0db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>educational-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "      <th>kfold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48837</th>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48838</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48839</th>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48840</th>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48841</th>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48842 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              workclass     education  educational-num      marital-status  \\\n",
       "0               Private  Some-college               10  Married-civ-spouse   \n",
       "1               Private       HS-grad                9            Divorced   \n",
       "2      Self-emp-not-inc     Bachelors               13  Married-civ-spouse   \n",
       "3               Private       HS-grad                9  Married-civ-spouse   \n",
       "4      Self-emp-not-inc     Bachelors               13  Married-civ-spouse   \n",
       "...                 ...           ...              ...                 ...   \n",
       "48837           Private  Some-college               10       Never-married   \n",
       "48838           Private       HS-grad                9             Widowed   \n",
       "48839           Private  Some-college               10  Married-civ-spouse   \n",
       "48840           Private     Bachelors               13  Married-civ-spouse   \n",
       "48841  Self-emp-not-inc       HS-grad                9            Divorced   \n",
       "\n",
       "              occupation    relationship   race  gender native-country  \\\n",
       "0                  Sales         Husband  White    Male  United-States   \n",
       "1        Exec-managerial       Unmarried  White  Female  United-States   \n",
       "2         Prof-specialty  Other-relative  White  Female  United-States   \n",
       "3           Craft-repair         Husband  White    Male              ?   \n",
       "4                  Sales         Husband  White    Male  United-States   \n",
       "...                  ...             ...    ...     ...            ...   \n",
       "48837  Handlers-cleaners       Own-child  White    Male  United-States   \n",
       "48838  Machine-op-inspct       Unmarried  White  Female  United-States   \n",
       "48839       Craft-repair         Husband  White    Male  United-States   \n",
       "48840    Exec-managerial         Husband  White    Male  United-States   \n",
       "48841              Sales   Not-in-family  White  Female  United-States   \n",
       "\n",
       "       income  kfold  \n",
       "0           0      0  \n",
       "1           0      0  \n",
       "2           1      0  \n",
       "3           0      0  \n",
       "4           1      0  \n",
       "...       ...    ...  \n",
       "48837       0      4  \n",
       "48838       0      4  \n",
       "48839       0      4  \n",
       "48840       0      4  \n",
       "48841       0      4  \n",
       "\n",
       "[48842 rows x 11 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92722d51-5d15-4ce4-b910-a8bbe2fac401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t1.0\n",
      "  (0, 21)\t1.0\n",
      "  (0, 30)\t1.0\n",
      "  (0, 43)\t1.0\n",
      "  (0, 58)\t1.0\n",
      "  (0, 63)\t1.0\n",
      "  (0, 73)\t1.0\n",
      "  (0, 75)\t1.0\n",
      "  (0, 115)\t1.0\n",
      "  (1, 4)\t1.0\n",
      "  (1, 18)\t1.0\n",
      "  (1, 29)\t1.0\n",
      "  (1, 43)\t1.0\n",
      "  (1, 52)\t1.0\n",
      "  (1, 68)\t1.0\n",
      "  (1, 71)\t1.0\n",
      "  (1, 74)\t1.0\n",
      "  (1, 115)\t1.0\n",
      "  (2, 2)\t1.0\n",
      "  (2, 21)\t1.0\n",
      "  (2, 30)\t1.0\n",
      "  (2, 43)\t1.0\n",
      "  (2, 52)\t1.0\n",
      "  (2, 63)\t1.0\n",
      "  (2, 73)\t1.0\n",
      "  :\t:\n",
      "  (39070, 26)\t1.0\n",
      "  (39070, 43)\t1.0\n",
      "  (39070, 51)\t1.0\n",
      "  (39070, 63)\t1.0\n",
      "  (39070, 73)\t1.0\n",
      "  (39070, 75)\t1.0\n",
      "  (39070, 115)\t1.0\n",
      "  (39071, 4)\t1.0\n",
      "  (39071, 18)\t1.0\n",
      "  (39071, 29)\t1.0\n",
      "  (39071, 43)\t1.0\n",
      "  (39071, 52)\t1.0\n",
      "  (39071, 63)\t1.0\n",
      "  (39071, 73)\t1.0\n",
      "  (39071, 75)\t1.0\n",
      "  (39071, 115)\t1.0\n",
      "  (39072, 6)\t1.0\n",
      "  (39072, 20)\t1.0\n",
      "  (39072, 40)\t1.0\n",
      "  (39072, 41)\t1.0\n",
      "  (39072, 60)\t1.0\n",
      "  (39072, 64)\t1.0\n",
      "  (39072, 73)\t1.0\n",
      "  (39072, 74)\t1.0\n",
      "  (39072, 115)\t1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8810573385785094\n",
      "  (0, 4)\t1.0\n",
      "  (0, 24)\t1.0\n",
      "  (0, 26)\t1.0\n",
      "  (0, 43)\t1.0\n",
      "  (0, 60)\t1.0\n",
      "  (0, 63)\t1.0\n",
      "  (0, 73)\t1.0\n",
      "  (0, 75)\t1.0\n",
      "  (0, 115)\t1.0\n",
      "  (1, 4)\t1.0\n",
      "  (1, 20)\t1.0\n",
      "  (1, 40)\t1.0\n",
      "  (1, 41)\t1.0\n",
      "  (1, 52)\t1.0\n",
      "  (1, 67)\t1.0\n",
      "  (1, 73)\t1.0\n",
      "  (1, 74)\t1.0\n",
      "  (1, 115)\t1.0\n",
      "  (2, 6)\t1.0\n",
      "  (2, 18)\t1.0\n",
      "  (2, 29)\t1.0\n",
      "  (2, 43)\t1.0\n",
      "  (2, 58)\t1.0\n",
      "  (2, 65)\t1.0\n",
      "  (2, 73)\t1.0\n",
      "  :\t:\n",
      "  (39070, 26)\t1.0\n",
      "  (39070, 43)\t1.0\n",
      "  (39070, 51)\t1.0\n",
      "  (39070, 63)\t1.0\n",
      "  (39070, 73)\t1.0\n",
      "  (39070, 75)\t1.0\n",
      "  (39070, 115)\t1.0\n",
      "  (39071, 4)\t1.0\n",
      "  (39071, 18)\t1.0\n",
      "  (39071, 29)\t1.0\n",
      "  (39071, 43)\t1.0\n",
      "  (39071, 52)\t1.0\n",
      "  (39071, 63)\t1.0\n",
      "  (39071, 73)\t1.0\n",
      "  (39071, 75)\t1.0\n",
      "  (39071, 115)\t1.0\n",
      "  (39072, 6)\t1.0\n",
      "  (39072, 20)\t1.0\n",
      "  (39072, 40)\t1.0\n",
      "  (39072, 41)\t1.0\n",
      "  (39072, 60)\t1.0\n",
      "  (39072, 64)\t1.0\n",
      "  (39072, 73)\t1.0\n",
      "  (39072, 74)\t1.0\n",
      "  (39072, 115)\t1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8787897415849424\n",
      "  (0, 4)\t1.0\n",
      "  (0, 24)\t1.0\n",
      "  (0, 26)\t1.0\n",
      "  (0, 43)\t1.0\n",
      "  (0, 60)\t1.0\n",
      "  (0, 63)\t1.0\n",
      "  (0, 73)\t1.0\n",
      "  (0, 75)\t1.0\n",
      "  (0, 115)\t1.0\n",
      "  (1, 4)\t1.0\n",
      "  (1, 20)\t1.0\n",
      "  (1, 40)\t1.0\n",
      "  (1, 41)\t1.0\n",
      "  (1, 52)\t1.0\n",
      "  (1, 67)\t1.0\n",
      "  (1, 73)\t1.0\n",
      "  (1, 74)\t1.0\n",
      "  (1, 115)\t1.0\n",
      "  (2, 6)\t1.0\n",
      "  (2, 18)\t1.0\n",
      "  (2, 29)\t1.0\n",
      "  (2, 43)\t1.0\n",
      "  (2, 58)\t1.0\n",
      "  (2, 65)\t1.0\n",
      "  (2, 73)\t1.0\n",
      "  :\t:\n",
      "  (39071, 26)\t1.0\n",
      "  (39071, 43)\t1.0\n",
      "  (39071, 51)\t1.0\n",
      "  (39071, 63)\t1.0\n",
      "  (39071, 73)\t1.0\n",
      "  (39071, 75)\t1.0\n",
      "  (39071, 115)\t1.0\n",
      "  (39072, 4)\t1.0\n",
      "  (39072, 18)\t1.0\n",
      "  (39072, 29)\t1.0\n",
      "  (39072, 43)\t1.0\n",
      "  (39072, 52)\t1.0\n",
      "  (39072, 63)\t1.0\n",
      "  (39072, 73)\t1.0\n",
      "  (39072, 75)\t1.0\n",
      "  (39072, 115)\t1.0\n",
      "  (39073, 6)\t1.0\n",
      "  (39073, 20)\t1.0\n",
      "  (39073, 40)\t1.0\n",
      "  (39073, 41)\t1.0\n",
      "  (39073, 60)\t1.0\n",
      "  (39073, 64)\t1.0\n",
      "  (39073, 73)\t1.0\n",
      "  (39073, 74)\t1.0\n",
      "  (39073, 115)\t1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8751725401579281\n",
      "  (0, 4)\t1.0\n",
      "  (0, 24)\t1.0\n",
      "  (0, 26)\t1.0\n",
      "  (0, 43)\t1.0\n",
      "  (0, 60)\t1.0\n",
      "  (0, 63)\t1.0\n",
      "  (0, 73)\t1.0\n",
      "  (0, 75)\t1.0\n",
      "  (0, 115)\t1.0\n",
      "  (1, 4)\t1.0\n",
      "  (1, 20)\t1.0\n",
      "  (1, 40)\t1.0\n",
      "  (1, 41)\t1.0\n",
      "  (1, 52)\t1.0\n",
      "  (1, 67)\t1.0\n",
      "  (1, 73)\t1.0\n",
      "  (1, 74)\t1.0\n",
      "  (1, 115)\t1.0\n",
      "  (2, 6)\t1.0\n",
      "  (2, 18)\t1.0\n",
      "  (2, 29)\t1.0\n",
      "  (2, 43)\t1.0\n",
      "  (2, 58)\t1.0\n",
      "  (2, 65)\t1.0\n",
      "  (2, 73)\t1.0\n",
      "  :\t:\n",
      "  (39071, 26)\t1.0\n",
      "  (39071, 43)\t1.0\n",
      "  (39071, 51)\t1.0\n",
      "  (39071, 63)\t1.0\n",
      "  (39071, 73)\t1.0\n",
      "  (39071, 75)\t1.0\n",
      "  (39071, 115)\t1.0\n",
      "  (39072, 4)\t1.0\n",
      "  (39072, 18)\t1.0\n",
      "  (39072, 29)\t1.0\n",
      "  (39072, 43)\t1.0\n",
      "  (39072, 52)\t1.0\n",
      "  (39072, 63)\t1.0\n",
      "  (39072, 73)\t1.0\n",
      "  (39072, 75)\t1.0\n",
      "  (39072, 115)\t1.0\n",
      "  (39073, 6)\t1.0\n",
      "  (39073, 20)\t1.0\n",
      "  (39073, 40)\t1.0\n",
      "  (39073, 41)\t1.0\n",
      "  (39073, 60)\t1.0\n",
      "  (39073, 64)\t1.0\n",
      "  (39073, 73)\t1.0\n",
      "  (39073, 74)\t1.0\n",
      "  (39073, 115)\t1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8789720657549095\n",
      "  (0, 4)\t1.0\n",
      "  (0, 24)\t1.0\n",
      "  (0, 26)\t1.0\n",
      "  (0, 43)\t1.0\n",
      "  (0, 60)\t1.0\n",
      "  (0, 63)\t1.0\n",
      "  (0, 73)\t1.0\n",
      "  (0, 75)\t1.0\n",
      "  (0, 115)\t1.0\n",
      "  (1, 4)\t1.0\n",
      "  (1, 20)\t1.0\n",
      "  (1, 40)\t1.0\n",
      "  (1, 41)\t1.0\n",
      "  (1, 52)\t1.0\n",
      "  (1, 67)\t1.0\n",
      "  (1, 73)\t1.0\n",
      "  (1, 74)\t1.0\n",
      "  (1, 115)\t1.0\n",
      "  (2, 6)\t1.0\n",
      "  (2, 18)\t1.0\n",
      "  (2, 29)\t1.0\n",
      "  (2, 43)\t1.0\n",
      "  (2, 58)\t1.0\n",
      "  (2, 65)\t1.0\n",
      "  (2, 73)\t1.0\n",
      "  :\t:\n",
      "  (39071, 40)\t1.0\n",
      "  (39071, 46)\t1.0\n",
      "  (39071, 56)\t1.0\n",
      "  (39071, 67)\t1.0\n",
      "  (39071, 73)\t1.0\n",
      "  (39071, 74)\t1.0\n",
      "  (39071, 115)\t1.0\n",
      "  (39072, 4)\t1.0\n",
      "  (39072, 18)\t1.0\n",
      "  (39072, 29)\t1.0\n",
      "  (39072, 43)\t1.0\n",
      "  (39072, 60)\t1.0\n",
      "  (39072, 63)\t1.0\n",
      "  (39072, 73)\t1.0\n",
      "  (39072, 75)\t1.0\n",
      "  (39072, 115)\t1.0\n",
      "  (39073, 4)\t1.0\n",
      "  (39073, 9)\t1.0\n",
      "  (39073, 37)\t1.0\n",
      "  (39073, 41)\t1.0\n",
      "  (39073, 51)\t1.0\n",
      "  (39073, 66)\t1.0\n",
      "  (39073, 73)\t1.0\n",
      "  (39073, 75)\t1.0\n",
      "  (39073, 115)\t1.0\n",
      "0.8817458947808354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# ohe_logres.py\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "\n",
    "def run(fold: int):\n",
    "    # サンプルのCSVファイルをpandasに読み込む\n",
    "    df = pd.read_csv(\"./adult_folds.csv\")\n",
    "    \n",
    "    # 数値を含む列の削除\n",
    "    num_cols = [\n",
    "        \"age\",\n",
    "        \"fnlwgt\",\n",
    "        #\"educational-num\",\n",
    "        \"capital-gain\",\n",
    "        \"capital-loss\",\n",
    "        \"hours-per-week\"\n",
    "    ]\n",
    "    df = df.drop(num_cols, axis=1)\n",
    "    \n",
    "    # 目的変数を0と1に置換\n",
    "    target_mapping = {\n",
    "        \"<=50K\": 0,\n",
    "        \">50K\": 1\n",
    "    }\n",
    "    df.loc[:, \"income\"] = df.income.map(target_mapping)\n",
    "    \n",
    "    features = [\n",
    "        f for f in df.columns if f not in (\"income\", \"kfold\")\n",
    "    \n",
    "    ]\n",
    "    \n",
    "    # 個々の特徴量についてのループ\n",
    "    for col in features:\n",
    "        # 欠損値を文字列で補完し、全ての値を文字列に置換\n",
    "        # 置換後の文字列をラベル＝ラベルIDとして使用する\n",
    "        df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
    "        \n",
    "    # 引数と一致しないkfoldのデータを学習データにする\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "\n",
    "    # 引数と一致するkfoldのデータを検証データにする\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    # 初期化\n",
    "    # 全ての項目をカテゴリ変数に変換する必要あり\n",
    "    ohe = preprocessing.OneHotEncoder()\n",
    "    \n",
    "    #train-testの結合\n",
    "    full_data = pd.concat([df_train[features], df_valid[features]],\n",
    "                          axis=0\n",
    "                         )\n",
    "\n",
    "    #oheを学習\n",
    "    ohe.fit(full_data[features])\n",
    "    \n",
    "    # 学習データセットを準備\n",
    "    x_train = ohe.transform(df_train[features])\n",
    "    \n",
    "    # 検証データセットを変換\n",
    "    x_valid = ohe.transform(df_valid[features])\n",
    "        \n",
    "    # モデルの初期化と学習\n",
    "    model = linear_model.LogisticRegression()\n",
    "    model.fit(x_train, df_train.income.values)\n",
    "    \n",
    "    \n",
    "    #  検証データセットを予測\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    \n",
    "    # AUCを算出\n",
    "    auc = metrics.roc_auc_score(df_valid.income.values, valid_preds)\n",
    "    \n",
    "    print(auc)\n",
    "    \n",
    "if __name__== \"__main__\":\n",
    "    for fold_ in range(5):\n",
    "        run(fold_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3df1e3eb-2258-401b-95ba-44f400863f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:25:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.8773120751978942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:25:56] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.8743154155383793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:26:01] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.8732755269460349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:26:12] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.8767377603232294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:26:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.8788226955426812\n"
     ]
    }
   ],
   "source": [
    "# lbl_xgb.py\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "def run(fold: int):\n",
    "    # サンプルのCSVファイルをpandasに読み込む\n",
    "    df = pd.read_csv(\"./adult_folds.csv\")\n",
    "    \n",
    "    # 数値を含む列の削除\n",
    "    num_cols = [\n",
    "        \"age\",\n",
    "        \"fnlwgt\",\n",
    "        #\"educational-num\",\n",
    "        \"capital-gain\",\n",
    "        \"capital-loss\",\n",
    "        \"hours-per-week\"\n",
    "    ]\n",
    "    df = df.drop(num_cols, axis=1)\n",
    "    \n",
    "    # 目的変数を0と1に置換\n",
    "    target_mapping = {\n",
    "        \"<=50K\": 0,\n",
    "        \">50K\": 1\n",
    "    }\n",
    "    df.loc[:, \"income\"] = df.income.map(target_mapping)\n",
    "    \n",
    "    features = [\n",
    "        f for f in df.columns if f not in (\"income\", \"kfold\")\n",
    "    \n",
    "    ]\n",
    "    \n",
    "    # 特徴量のエンコーディング\n",
    "    for col in features:\n",
    "        # 欠損値を文字列で補完し、全ての値を文字列に置換\n",
    "        # 置換後の文字列をラベル＝ラベルIDとして使用する\n",
    "        df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
    "\n",
    "    # 特徴量のラベルエンコーディング\n",
    "    for col in features:\n",
    "        # 初期化\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        \n",
    "        # ラベルエンコーダの学習\n",
    "        lbl.fit(df[col])\n",
    "        \n",
    "        # データセットの変換\n",
    "        df.loc[:, col] = lbl.transform(df[col])\n",
    "        \n",
    "        \n",
    "    # 引数と一致しないkfoldのデータを学習データにする\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "\n",
    "    # 引数と一致するkfoldのデータを検証データにする\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    # 学習データセットを準備\n",
    "    x_train = df_train[features].values\n",
    "    \n",
    "    # 検証データセットを変換\n",
    "    x_valid = df_valid[features].values\n",
    "        \n",
    "    # モデルの初期化と学習\n",
    "    model = xgb.XGBClassifier(\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    model.fit(x_train, df_train.income.values)\n",
    "    \n",
    "    \n",
    "    #  検証データセットを予測\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    \n",
    "    # AUCを算出\n",
    "    auc = metrics.roc_auc_score(df_valid.income.values, valid_preds)\n",
    "    \n",
    "    print(auc)\n",
    "    \n",
    "if __name__== \"__main__\":\n",
    "    for fold_ in range(5):\n",
    "        run(fold_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08b2163e-c1bf-4ce8-9f91-e796a6c4039a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:28:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.8773120751978942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:28:35] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.8743154155383793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:28:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.8732755269460349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:28:46] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.8767377603232294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:28:51] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.8788226955426812\n"
     ]
    }
   ],
   "source": [
    "# lbl_xgb_num.py\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "def run(fold: int):\n",
    "    # サンプルのCSVファイルをpandasに読み込む\n",
    "    df = pd.read_csv(\"./adult_folds.csv\")\n",
    "    \n",
    "    # 数値を含む列の削除\n",
    "    num_cols = [\n",
    "        \"age\",\n",
    "        \"fnlwgt\",\n",
    "        #\"educational-num\",\n",
    "        \"capital-gain\",\n",
    "        \"capital-loss\",\n",
    "        \"hours-per-week\"\n",
    "    ]\n",
    "    df = df.drop(num_cols, axis=1)\n",
    "    \n",
    "    # 目的変数を0と1に置換\n",
    "    target_mapping = {\n",
    "        \"<=50K\": 0,\n",
    "        \">50K\": 1\n",
    "    }\n",
    "    df.loc[:, \"income\"] = df.income.map(target_mapping)\n",
    "    \n",
    "    features = [\n",
    "        f for f in df.columns if f not in (\"income\", \"kfold\")\n",
    "    \n",
    "    ]\n",
    "    \n",
    "    # 特徴量のエンコーディング\n",
    "    for col in features:\n",
    "        # 欠損値を文字列で補完し、全ての値を文字列に置換\n",
    "        # 置換後の文字列をラベル＝ラベルIDとして使用する\n",
    "        if col not in num_cols:\n",
    "            df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
    "\n",
    "    # 特徴量のラベルエンコーディング\n",
    "    for col in features:\n",
    "        if col not in num_cols:\n",
    "            # 初期化\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "\n",
    "            # ラベルエンコーダの学習\n",
    "            lbl.fit(df[col])\n",
    "\n",
    "            # データセットの変換\n",
    "            df.loc[:, col] = lbl.transform(df[col])\n",
    "        \n",
    "        \n",
    "    # 引数と一致しないkfoldのデータを学習データにする\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "\n",
    "    # 引数と一致するkfoldのデータを検証データにする\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    # 学習データセットを準備\n",
    "    x_train = df_train[features].values\n",
    "    \n",
    "    # 検証データセットを変換\n",
    "    x_valid = df_valid[features].values\n",
    "        \n",
    "    # モデルの初期化と学習\n",
    "    model = xgb.XGBClassifier(\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    model.fit(x_train, df_train.income.values)\n",
    "    \n",
    "    \n",
    "    #  検証データセットを予測\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    \n",
    "    # AUCを算出\n",
    "    auc = metrics.roc_auc_score(df_valid.income.values, valid_preds)\n",
    "    \n",
    "    print(auc)\n",
    "    \n",
    "if __name__== \"__main__\":\n",
    "    for fold_ in range(5):\n",
    "        run(fold_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "185018e5-6b4b-4b5f-8540-a16eaf5511c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:49:27] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.8766071006956615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:49:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.8712445344042867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:50:03] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.8722561645011729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:50:13] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.876179147975956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:50:24] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.8776732819704799\n"
     ]
    }
   ],
   "source": [
    "# lbl_xgb_num_feat.py\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import itertools\n",
    "\n",
    "def feature_engineering(df, cat_cols):\n",
    "    # リスト内の全ての2値の組みを生成\n",
    "    combi = list(itertools.combinations(cat_cols, 2))\n",
    "    for c1, c2 in combi:\n",
    "        df.loc[:, c1 + \"_\" + c2] = df[c1].astype(str) + \"_\" + df[c2].astype(str)\n",
    "        \n",
    "    return df\n",
    "        \n",
    "\n",
    "def run(fold: int):\n",
    "    # サンプルのCSVファイルをpandasに読み込む\n",
    "    df = pd.read_csv(\"./adult_folds.csv\")\n",
    "    \n",
    "    # 数値を含む列の削除\n",
    "    num_cols = [\n",
    "        \"age\",\n",
    "        \"fnlwgt\",\n",
    "        #\"educational-num\",\n",
    "        \"capital-gain\",\n",
    "        \"capital-loss\",\n",
    "        \"hours-per-week\"\n",
    "    ]\n",
    "    df = df.drop(num_cols, axis=1)\n",
    "    \n",
    "    # 目的変数を0と1に置換\n",
    "    target_mapping = {\n",
    "        \"<=50K\": 0,\n",
    "        \">50K\": 1\n",
    "    }\n",
    "    df.loc[:, \"income\"] = df.income.map(target_mapping)\n",
    "    \n",
    "    # 質的変数の列\n",
    "    cat_cols = [\n",
    "        c for c in df.columns if c not in num_cols\n",
    "        and c not in (\"income\", \"kfold\")\n",
    "    ]\n",
    "    \n",
    "    # 新しい質的変数を特徴量に追加\n",
    "    df = feature_engineering(df, cat_cols)\n",
    "    \n",
    "    features = [\n",
    "        f for f in df.columns if f not in (\"income\", \"kfold\")\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    # 特徴量のエンコーディング\n",
    "    for col in features:\n",
    "        # 欠損値を文字列で補完し、全ての値を文字列に置換\n",
    "        # 置換後の文字列をラベル＝ラベルIDとして使用する\n",
    "        if col not in num_cols:\n",
    "            df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
    "\n",
    "    # 特徴量のラベルエンコーディング\n",
    "    for col in features:\n",
    "        if col not in num_cols:\n",
    "            # 初期化\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "\n",
    "            # ラベルエンコーダの学習\n",
    "            lbl.fit(df[col])\n",
    "\n",
    "            # データセットの変換\n",
    "            df.loc[:, col] = lbl.transform(df[col])\n",
    "        \n",
    "        \n",
    "    # 引数と一致しないkfoldのデータを学習データにする\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "\n",
    "    # 引数と一致するkfoldのデータを検証データにする\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    # 学習データセットを準備\n",
    "    x_train = df_train[features].values\n",
    "    \n",
    "    # 検証データセットを変換\n",
    "    x_valid = df_valid[features].values\n",
    "        \n",
    "    # モデルの初期化と学習\n",
    "    model = xgb.XGBClassifier(\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    model.fit(x_train, df_train.income.values)\n",
    "    \n",
    "    \n",
    "    #  検証データセットを予測\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    \n",
    "    # AUCを算出\n",
    "    auc = metrics.roc_auc_score(df_valid.income.values, valid_preds)\n",
    "    \n",
    "    print(auc)\n",
    "    \n",
    "if __name__== \"__main__\":\n",
    "    for fold_ in range(5):\n",
    "        run(fold_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6db76f2a-a322-42f2-9682-34c800c26a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:53:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.9304215261730993\n",
      "[14:53:47] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9247271360733174\n",
      "[14:53:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9232791633102996\n",
      "[14:53:50] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9238410866780831\n",
      "[14:53:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.929210237537218\n"
     ]
    }
   ],
   "source": [
    "# target_encoding.py\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import itertools\n",
    "import copy \n",
    "\n",
    "\n",
    "def mean_target_encoding(data):\n",
    "    \n",
    "    # データセットのコピー\n",
    "    df = copy.deepcopy(data)\n",
    "    \n",
    "    # 数値を含む列\n",
    "    num_cols = [\n",
    "        \"age\",\n",
    "        \"fnlwgt\",\n",
    "        #\"educational-num\",\n",
    "        \"capital-gain\",\n",
    "        \"capital-loss\",\n",
    "        \"hours-per-week\"\n",
    "    ]  \n",
    "\n",
    "    # 目的変数を0と1に置換\n",
    "    target_mapping = {\n",
    "        \"<=50K\": 0,\n",
    "        \">50K\": 1\n",
    "    }\n",
    "    df.loc[:, \"income\"] = df.income.map(target_mapping)  \n",
    "    \n",
    "    # 目的変数とkfold列を除いて特徴量を作成\n",
    "    features = [\n",
    "        f for f in df.columns if f not in (\"income\", \"kfold\")\n",
    "        and f not in num_cols\n",
    "    ]\n",
    "    \n",
    "    # 特徴量のエンコーディング\n",
    "    for col in features:\n",
    "        # 欠損値を文字列で補完し、全ての値を文字列に置換\n",
    "        # 置換後の文字列をラベル＝ラベルIDとして使用する\n",
    "        if col not in num_cols:\n",
    "            df.loc[:, col] = df[col].astype(str).fillna(\"NONE\")\n",
    "\n",
    "    # 特徴量のラベルエンコーディング\n",
    "    for col in features:\n",
    "        if col not in num_cols:\n",
    "            # 初期化\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "\n",
    "            # ラベルエンコーダの学習\n",
    "            lbl.fit(df[col])\n",
    "\n",
    "            # データセットの変換\n",
    "            df.loc[:, col] = lbl.transform(df[col]) \n",
    "    \n",
    "    # 検証データセット格納リスト\n",
    "    encoded_dfs = []\n",
    "\n",
    "    \n",
    "    \n",
    "    # 全ての分割についてループ\n",
    "    for fold in range(5):\n",
    "        # データセットの準備\n",
    "        df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "        df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "        \n",
    "        # 全ての特徴量についてループ\n",
    "        for column in features:\n",
    "            # カテゴリごとの目的変数の平均についての辞書を作成\n",
    "            mapping_dict = dict(\n",
    "                df_train.groupby(column)[\"income\"].mean()\n",
    "            )\n",
    "            # 列の末尾にencをつけた名前で新列を作成\n",
    "            df_valid.loc[\n",
    "                :, column + \"_enc\"\n",
    "            ] = df_valid[column].map(mapping_dict)\n",
    "        \n",
    "        # リストに格納\n",
    "        encoded_dfs.append(df_valid)\n",
    "        \n",
    "    # 結合したデータセットを返す\n",
    "    encoded_dfs = pd.concat(encoded_dfs, axis=0)\n",
    "    return encoded_dfs\n",
    "    \n",
    "    \n",
    "\n",
    "def run(df, fold):\n",
    "    # 引数と一致しないkfoldのデータを学習データにする\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True)\n",
    "\n",
    "    # 引数と一致するkfoldのデータを検証データにする\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True)\n",
    "    \n",
    "    # 目的変数とkfold列を除いて特徴量を作成\n",
    "    features = [\n",
    "        f for f in df.columns if f not in (\"income\", \"kfold\")\n",
    "    ]\n",
    "    \n",
    "    \n",
    "    # 学習データセットを準備\n",
    "    x_train = df_train[features].values\n",
    "    \n",
    "    # 検証データセットを変換\n",
    "    x_valid = df_valid[features].values\n",
    "        \n",
    "    # モデルの初期化と学習\n",
    "    model = xgb.XGBClassifier(\n",
    "        n_jobs=-1\n",
    "        ,max_depth=7\n",
    "    )\n",
    "    model.fit(x_train, df_train.income.values)\n",
    "    \n",
    "    #  検証データセットを予測\n",
    "    valid_preds = model.predict_proba(x_valid)[:, 1]\n",
    "    \n",
    "    # AUCを算出\n",
    "    auc = metrics.roc_auc_score(df_valid.income.values, valid_preds)\n",
    "    \n",
    "    print(auc)\n",
    "    \n",
    "if __name__== \"__main__\":\n",
    "    # データの読み込み\n",
    "    df = pd.read_csv(\"./adult_folds.csv\")\n",
    "    \n",
    "    #エンコーディングの実行\n",
    "    df = mean_target_encoding(df)\n",
    "    \n",
    "    # 各分割でモデル実行\n",
    "    for fold_ in range(5):\n",
    "        run(df, fold_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "625c0065-a1c4-4622-b056-f9c1b1eb5401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
